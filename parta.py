# -*- coding: utf-8 -*-
"""parta.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GWyeoMJxvJn4m5ByKgOqV0J2UTpDQYcv

# **Setup**
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler,MinMaxScaler,MaxAbsScaler
from sklearn.model_selection import train_test_split,GridSearchCV
from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score,roc_curve,auc
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
import warnings
from sklearn.exceptions import ConvergenceWarning
from joblib import parallel_backend

np.random.seed(42)

with warnings.catch_warnings():
    warnings.filterwarnings("ignore", category=ConvergenceWarning)

def eval_metrics(true,pred,avg):
  acc = accuracy_score(true,pred)
  prec = precision_score(true,pred, average=avg)
  recall = recall_score(true,pred, average=avg)
  f1 = f1_score(true,pred, average=avg)
  print('Accuracy: ',acc,", Precision: ",prec,", Recall: ",recall,", F1: ",f1)
  return [acc,prec,recall,f1]

# Plot ROC curve and display AUC
def plot_roc_curves(val, predprobs):
    plt.figure()
    name = ['logistic regression','random forest','svm']
    for i,prob in enumerate(predprobs):
        fpr,tpr,thresholds = roc_curve(y_test, prob[:,1], pos_label=1)
        plt.plot(fpr, tpr, label='{} (AUC={:.3f})'.format(name[i],auc(fpr, tpr)))
        plt.plot([0, 1], [0, 1], '--', color = 'grey')

        plt.xlim([0, 1])
        plt.ylim([0, 1])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('ROC Curve')
        plt.legend()
    plt.show()

"""# **Train Data Preparation**"""

train_data_bin = pd.read_csv('TrainingDataBinary.csv')
features = train_data_bin.columns.values
labels_bin = train_data_bin['marker']
train_data_bin = train_data_bin.drop(['marker'], axis=1)
train_data_bin.head()

train_data_mult = pd.read_csv('TrainingDataMulti.csv')
features = train_data_mult.columns.values
labels_mult = train_data_mult['marker']
train_data_mult = train_data_mult.drop(['marker'], axis=1)
train_data_mult.head()

"""# **Part A**

## **Training**
"""

results_bin = []
pred_probs_bin = []

X_bin = StandardScaler().fit_transform(train_data_bin)

x_train,x_test,y_train,y_test = train_test_split(X_bin,labels_bin,test_size=0.3,random_state=42)

lr = LogisticRegression(random_state=42)
lr_params = {
    "penalty":['l1','l2'],
    "C":[0.1,1.0,10.0,100.0],
    "solver":['liblinear','saga']
}

lr_gscv = GridSearchCV(lr,lr_params,cv=3,verbose=3,n_jobs=-1)
with parallel_backend('multiprocessing'):
    lr_gscv.fit(x_train,y_train)
print(f'Best logistic regression parameters are:\n {lr_gscv.best_params_}')

best_lr = lr_gscv.best_estimator_
best_lr.fit(x_train,y_train)
lr_pred = best_lr.predict(x_test)
pred_probs_bin.append(best_lr.predict_proba(x_test))
results_bin.append(eval_metrics(y_test,lr_pred,'binary'))

rf = RandomForestClassifier(random_state=42)
rf_params = {
    "n_estimators":np.arange(2,60),
    "min_samples_split":np.arange(2,7)
}

rf_gscv = GridSearchCV(rf,rf_params,cv=3,verbose=3,n_jobs=-1)
with parallel_backend('multiprocessing'):
    rf_gscv.fit(x_train,y_train)
print(f'Best random forest parameters are:\n {rf_gscv.best_params_}')

best_rf = rf_gscv.best_estimator_
best_rf.fit(x_train,y_train)
rf_pred = best_rf.predict(x_test)
pred_probs_bin.append(best_rf.predict_proba(x_test))
results_bin.append(eval_metrics(y_test,rf_pred,'binary'))

svm = SVC(random_state=42,probability=True)
svm_params = {
    "C":[0.01,0.1,1,10,100],
    "kernel":['linear','rbf']
}
svm_gscv = GridSearchCV(svm,svm_params,cv=3,verbose=3,n_jobs=-1)
with parallel_backend('multiprocessing'):
    svm_gscv.fit(x_train,y_train)
print(f'Best svm parameters are:\n {svm_gscv.best_params_}')

best_svm = svm_gscv.best_estimator_
best_svm.fit(x_train,y_train)
svm_pred = best_svm.predict(x_test)
pred_probs_bin.append(best_svm.predict_proba(x_test))
results_bin.append(eval_metrics(y_test,svm_pred,'binary'))

print(results_bin)
bin_table = pd.DataFrame(np.array(results_bin),columns=['Accuracy','Precision','Recall','F1'], index=['Logistic Regression','Random Forest','SVM'])
bin_table.head()

plot_roc_curves(y_test,pred_probs_bin)

"""## **Testing**"""

test_data_bin = pd.read_csv('TestingDataBinary.csv')
test_data_bin.head()

best_rf.fit(X_bin,labels_bin)
pred = best_rf.predict(test_data_bin.values)
out = test_data_bin.copy()
out['marker'] = pred
# out.head()
print(pred)
# out.to_csv("TestingResultsBinary.csv", index=False)

"""# **Part B**

## **Training**
"""

results_mult = []
pred_probs_mult = []

X_mult = StandardScaler().fit_transform(train_data_mult)

x_train,x_test,y_train,y_test = train_test_split(X_mult,labels_mult,test_size=0.3,random_state=42)

lr = LogisticRegression(random_state=42)
lr_params = {
    "penalty":['l1','l2'],
    "C":[0.1,1.0,10.0,100.0],
    "solver":['liblinear','saga']
}

lr_gscv = GridSearchCV(lr,lr_params,cv=3,verbose=3,n_jobs=-1)
with parallel_backend('multiprocessing'):
    lr_gscv.fit(x_train,y_train)
print(f'Best logistic regression parameters are:\n {lr_gscv.best_params_}')

best_lr = lr_gscv.best_estimator_
best_lr.fit(x_train,y_train)
lr_pred = best_lr.predict(x_test)
pred_probs_mult.append(best_lr.predict_proba(x_test))
results_mult.append(eval_metrics(y_test,lr_pred,avg='macro'))

rf = RandomForestClassifier(random_state=42)
rf_params = {
    "n_estimators":np.arange(2,60),
    "min_samples_split":np.arange(2,7)
}

rf_gscv = GridSearchCV(rf,rf_params,cv=3,verbose=3,n_jobs=-1)
with parallel_backend('multiprocessing'):
    rf_gscv.fit(x_train,y_train)
print(f'Best random forest parameters are:\n {rf_gscv.best_params_}')

best_rf = rf_gscv.best_estimator_
best_rf.fit(x_train,y_train)
rf_pred = best_rf.predict(x_test)
pred_probs_mult.append(best_rf.predict_proba(x_test))
results_mult.append(eval_metrics(y_test,rf_pred,'macro'))

svm = SVC(random_state=42,probability=True)
svm_params = {
    "C":[0.01,0.1,1,10,100],
    "kernel":['linear','rbf']
}
svm_gscv = GridSearchCV(svm,svm_params,cv=3,verbose=3,n_jobs=-1)
with parallel_backend('multiprocessing'):
    svm_gscv.fit(x_train,y_train)
print(f'Best svm parameters are:\n {svm_gscv.best_params_}')

best_svm = svm_gscv.best_estimator_
best_svm.fit(x_train,y_train)
svm_pred = best_svm.predict(x_test)
pred_probs_mult.append(best_svm.predict_proba(x_test))
results_mult.append(eval_metrics(y_test,svm_pred,'macro'))

mult_table = pd.DataFrame(np.array(results_mult),columns=['Accuracy','Precision','Recall','F1'],index=['Logistic Regression','Random Forest','SVM'])
mult_table.head()

plot_roc_curves(y_test,pred_probs_mult)

"""## **Testing**"""

test_data_mult = pd.read_csv('TestingDataMulti.csv')
test_data_mult.head()

best_rf.fit(X_mult,labels_mult)
pred = best_rf.predict(test_data_mult.values)
out = test_data_mult.copy()
out['marker'] = pred
# out.head()
print(pred)
# out.to_csv("TestingResultsBinary.csv", index=False)